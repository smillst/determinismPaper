\section{A type system for determinism}\label{design}

This section presents the key aspects of the design of our type system,
called \ourTypeSystem, in the context of a core calculus for an
object-oriented language.


\subsection{Preliminaries and notation}

%% This section is too basic, and therefore is boring because most readers
%% will already know it.  It also delays the interesting parts of the paper
%% for too long.  We can introduce concepts as they are needed in the rest
%% of the paper.
% \subsection{Type checking background}\label{type-checking}
% The major components of a type system include: 1) \textit{types}, 2) \textit{subtyping rules}, and 3) \textit{dataflow analysis}.
% A \textit{type} serves as an abstraction for the set of acceptable values for any expression. The types in a type system form a lattice of finite height. 
% The hierarchy of types in this lattice defines subtyping relationships among them.
% In our framework, we require every type hierarchy to define a unique\<@Top> and a \<@Bottom> element. This ensures that
% any given pair of types has a \textit{least upper bound} and a \textit{greatest lower bound}.
% Throughout this paper, we use the notation \<@A> <: \<@B> to denote that type \<@A> is a subtype of type \<@B>.
% As an illustration of the type hierarchy, consider the lattice of types shown in \cref{fig-example-lattice}.
% \begin{figure}
%     \begin{center}
%         \includegraphics[scale=0.15]{lattice}
%     \end{center}
%     \caption{Example type hierarchy}
%     \label{fig-example-lattice}
% \end{figure}
% In this type system, \<@C> is a subtype of \<@A> as well as \<@B> and types \<@A> and \<@B> are incomparable.
% The type checker now performs additional type checking (similar to javac's type checking) with respect to this type hierarchy
% and reports any violations. The snippet in \cref{code-invalid1} would result in an error at the assignment statements:
% \begin{figure}
%     \begin{verbatim}
%     @A int x; @B int y; @C int z;
%     x = y;    // Because types @A and @B are incomparable.
%     z = x;    // Because @C is a subtype of @A.
%     \end{verbatim}
% \caption{Example: Invalid assignment}
% \label{code-invalid1}
% \end{figure}
% 
% %Method overriding and example
% For method overriding, the usual rules apply for parameters and arguments i.e covariant subtyping for parameters
% and contravariant subtyping for return types. Consider the example in \cref{code-invalid2} where method \<foo> of \<class X> is overridden
% in \<class Y>.
% \begin{figure}
%     \begin{verbatim}
%     class X {
%         @B int foo(@C int param) {}
%     }
%     class Y extends X {
%         @C int foo(@B int param) {}
%     }
%     \end{verbatim}
%     \caption{Example: Invalid Method override}
%     \label{code-invalid2}
% \end{figure}
% 
% The overriding method is invalid for two reasons: type of the parameter (\<@B>) is not a subtype of the parameter type in the overridden method (\<@C>) and the return type (\<@C>) is not a supertype of the return type of the overridden method (\<@B>).
% 
% %collections type parameters - invariant
% Collection types are invariant. So, if a \<List> x is declared as \codeid{@A List<@A String> x;} and another \<List y> is declared
% as  \codeid{@A List<@B String> y;}, writing \<x = y> would result in an error.
% 
% %covariant array types
% Arrays follow covariant subtyping rules in java. Therefore, the assignment statement \<@A int @A[] x = y;> where \<y> was 
% declared as \<@B int @A[] y> would type check without any warning.



%\todo{Need some background around here about what a type qualifier is,
%  how it is represented in Java, and how to read a type \<@Q BaseType>.}

%\todo{Greek letters go after this paragraph.}

\begin{figure}
  \newcommand{\bnfalt}{\ \ |\ \ }
  \begin{tabular}{lcll}
    $C$ & ::= & \<Int>\bnfalt \<String>\bnfalt \<Collection>\bnfalt \<List>\bnfalt \<Set>\bnfalt \<Map> & class name \\
    $\kappa$ & ::= & \<NonDet>\bnfalt \<OrderNonDet>\bnfalt\<Det> & type qualifier \\
    $\tau$ & ::= & $\kappa\ \beta$ & \mbox{type} \\
    $\beta$ & ::= & $C$\bnfalt $C\angles{\overline{\tau}}$ 
    & \mbox{unqualified type}
  \end{tabular}
  \caption{Grammar of types}
  \label{fig:grammar}
\end{figure}

In a type system,
a \textit{type} represents a set of values.  It abstracts or restricts the
set of possible run-time values that an expression may evaluate to.
A programming language provides \emph{basetypes}, such as \<Int>.
A \textit{type qualifier} on a basetype adds additional constraints;
that is, it reduces the size of the set of values.
An example type qualifier is \<Positive>, and a type (which combines a qualifier
and a basetype) is \<Positive Int>.
A polymorphic type abstraction such as \<List> can be instantiated by a type argument,
as in \ptype{List}{Positive Int}.

\Cref{fig:grammar} formalizes these notions.
\Cref{fig:grammar}'s $\beta$ is not a basetype as described above:  $\beta$
lacks a top-level type, but any type arguments are full types
$\tau$.  This paper does not formally define basetype, and uses $\beta$,
for simplicity of exposition.
In our core calculus, a type $\tau$ always has a qualifier.
Our implementation, \theDeterminismChecker, uses inference and defaults to
permit users to omit type qualifiers\todo{Forward reference}.


A type checker verifies the types written in a program.
A type qualifier constrain the set of possible run-time values, that is,
$\kappa \ /beta \sqsubseteq \beta$.
As a result, a qualifier type system does not allow any behavior that the
original type system does not.
However, the qualifier type system may reject more programs, and thus
affords stronger guarantees.
(Our implementation \theDeterminismChecker runs the underlying base type
system, then issues additional errors and warnings.)
\todo{Some qualifier type systems can be defined independently of the underlying
type system.  We don't do that because there are interactions between the
basetypes and the type qualifiers.  This allows greater precision, which
is important in practice.}


\begin{figure}
    \bigskip

    $\infer{\Det \sqsubseteq \OrderNonDet}{}
    \quad\quad
    \infer{\OrderNonDet \sqsubseteq \NonDet}{}$
    
    \bigskip

    $\infer{\kappa_1 \beta \sqsubseteq \kappa_2 \beta}{\kappa_1 \sqsubseteq \kappa_2}
    \quad\quad
    \infer{\kappa \beta_1 \sqsubseteq \kappa \beta_2}{\beta_1 \sqsubseteq \beta_2}$
    
    
    \caption{Subtyping rules for \ourTypeSystem.  $\sqsubseteq$ is overloaded for classes,
    type qualifiers, types, and unqualified types $\beta$.}
    \label{fig:typecheck-rules}
\end{figure}

\begin{figure}
    \bigskip

    $\infer{\tau_1 \sqsubseteq \tau_3}{\tau_1 \sqsubseteq \tau_2 \quad \tau_2 \sqsubseteq \tau_3}
    \quad\quad
    \infer[\rulename{subtyping}]{\Gamma \vdash x : \tau_2}{\Gamma \vdash x : \tau_1 & \tau_1 \sqsubseteq \tau_2}$
    
    \bigskip
    
    $\infer[\rulename{method call}]{\|method|(\overline{a_i}) : \tau_r}{\tau_r \  \|method|(\overline{\tau_i \  p_i}) & \overline{a_i : \tau_i}}$
    
    \bigskip
    
    $\infer[\rulename{invariant type arg}]{C_1\angles{\overline{\tau_i}}
      \sqsubseteq C_2\angles{\overline{\tau_i}}}{C_1 \sqsubseteq C_2}$
    
    \caption{A sampling of standard typing rules.  We omit other standard rules,
    for brevity.}
    \label{typecheck-rules-standard}
\end{figure}

%\todo{Define the Greek.  For example:
%
%  A type $\tau = \kappa\ \beta$ consists of a qualifier and a basetype.
%  Neither may be omitted.
%
%  $\beta$ is a type that lacks its type qualifier, but has type qualifiers
%  on any type arguments:
%  $\beta = C | C\angles{\overline{\tau}}$.
%  }

\Cref{typecheck-rules-standard} shows a sample of standard typing rules for
an object-oriented programming language.



\OurTypeSystem checks all the standard typing rules including the ones shown in \cref{typecheck-rules-standard} with
the only difference of having an additional type qualifier on each of the basetypes.


\subsection{Determinism types}\label{type-hierarchy}

%% Reinstate wrapfigure later.  But, if it spans pages, every following
%% page to the end of the document is narrowed to accommodate it.
% \begin{wrapfigure}{R}{0.3\textwidth}
\begin{figure}
    \begin{center}
        \includegraphics[scale=0.37]{detHierarchy}
    \end{center}
    \caption{Determinism type qualifier hierarchy}
    \label{fig:determinism-hierarchy}
\end{figure}
% \end{wrapfigure}

The core of the determinism type system is the following type qualifiers:
%\todo{introduce just @Det and @NonDet first, and then @OrderNonDet after polymorphism.}
\begin{itemize}
    \item \<NonDet> indicates
    that the expression might have different values in two different executions.
    \item \<OrderNonDet> indicates that the expression is a collection or
      map that contains the same elements in every execution, but possibly
      in a different order.
    \item \<Det> indicates that the expression evaluates to equal values in
      all executions; for an unordered collection such as a set, iteration
      also yields the values in the same order.
\end{itemize}
\Cref{fig:typecheck-rules,fig:determinism-hierarchy} show their subtyping relationship.

\<OrderNonDet> may only be written on collections and maps.

A map is a dictionary or associative array, such as a hash table.
\OurTypeSystem largely treats a map as a collection of key--value pairs.

Both collections and maps may be \<Det>, \<OrderNonDet>, or \<NonDet>, and
the element types can be specified independently of the collection type,
including qualifiers.

%\todo{A type $\tau$ is represented as $\kappa \ \beta$
%where $\kappa$ is a type qualifier (that is, \<NonDet>, \<OrderNonDet>, or
%\<Det>) and $\beta$ is a Java basetype.}


\subsection{Collection types}\label{collection-rules}

\subsubsection{Type well-formedness}

%\todo{Note that the \rulename{ordernondet} versions also handle \<Det>,
%  because $\<Det> \sqsubseteq \<OrderNonDet>$.}

\begin{figure}
    $\infer[\rulename{noncollection}]
    {\wellformed{\kappa \  \beta}}
    {\kappa \in \{ \<Det>, \<NonDet> \} & \beta \not\sqsubseteq \<Collection> & \beta \not\sqsubseteq \<Map>}$
    
    \bigskip
    
    $\infer[\rulename{ordernondet collection}]
    {\wellformed{\kappa_c \  \beta_c \angles{\kappa_e \ \beta_e}}}
    {\kappa_c \sqsubseteq \|OrderNonDet| & \kappa_e \sqsubseteq \kappa_c &
      \beta_c \sqsubseteq \<Collection> & \wellformed{\kappa_e \ \beta_e}}$
    
    \bigskip
    
    $\infer[\rulename{nondet collection}]
    {\wellformed{\|NonDet| \ C\angles{\|NonDet| \ \beta_e}}}
    {C \sqsubseteq \<Collection> & \wellformed{\|NonDet| \ \beta_e}}$
    
    \bigskip
    
%      $\infer[\rulename{ordernondet array}]{\wellformed{\kappa_e \ \beta_e \ \  \kappa_a []}}{\kappa_a \sqsubseteq \|OrderNonDet| & \kappa_e \sqsubseteq \kappa_a }$
%     
%     \bigskip
%     
%     $\infer[\rulename{nondet array}]{\wellformed{\|NonDet| \ \beta_e \ \  \|NonDet| []}}{}$
%     
%     \bigskip
    
    $\infer[\rulename{ordernondet map}]
    {\wellformed{\kappa_m \  \beta_m \angles{\kappa_k \ \beta_k, \kappa_v \ \beta_v}}}
    {\kappa_m \sqsubseteq \|OrderNonDet|
      & \kappa_k \sqsubseteq \kappa_m
      & \kappa_v \sqsubseteq \kappa_m
      & \beta_m \sqsubseteq \<Map>
      & \wellformed{\kappa_k \ \beta_k}
      & \wellformed{\kappa_v \ \beta_v}
    }$
    
    \bigskip
    
    $\infer[\rulename{nondet map}]
    {\wellformed{\|NonDet| \ \beta_m\angles{\|NonDet| \ \beta_k, \|NonDet| \ \beta_v}}}
    {\beta_m \sqsubseteq \<Map> & \wellformed{\|NonDet| \ \beta_k} & \wellformed{\|NonDet| \ \beta_v}}$
    
    \caption{Type well formedness}

%\todo{\todo{I think this will be OK, by redefining $\beta$.}
%  The collection rules do not permit nested collections; similarly, the
%  (currently commented out) array rules did not permit any two-dimensional
%  array to be well-formed.  There is a bigger issue here.
%  Consider the ``nondet collection'' rule.  $\beta_c$ is a class (we need
%  to use a different symbol for it, probably $c$), but $\beta_e$ should be
%  a full type, which might contain type qualifiers within it.  (Actually,
%  $\|NonDet|\ \beta_e$ is a type, not $\beta_e$ itself.)  So, there should
%  be an antecedent stating that $\|NonDet| \beta_e$ is well-formed, and
%  for the ``ordernondet collection'' rule stating that $\kappa_e \beta_e$
%  is well-formed.  Likewise, antecedents are needed for the map rules.
%  Otherwise, these rules permit construction of $\<Map>\angles{\tau'}$
%  where $\tau'$ is itself not well-defined.}

  \label{type-validity}
\end{figure}

\Cref{type-validity} shows the type well formedness
%\todo{The caption says
%  ``type well formedness''.  Choose one term and use it consistently
%  throughout.}
rules of \ourTypeSystem. 
(For brevity, we use ``valid'' synonymously with ``well-formed'' and
``invalid'' synonymously with ``non-well-formed''.)
As stated in the rule \rulename{noncollection}, the types \<Det> and \<NonDet>
can be written on any non-collection Java basetype. 

\begin{figure}
    \centering
    \begin{tabular}{|l|l|l|l|l|}
        \cline{3-5}
        \multicolumn{2}{c|}{~}  &  \multicolumn{3}{c|}{Element type} \\ \cline{3-5}
        \multicolumn{2}{c|}{~}  & NonDet     & OrderNonDet & Det \\ \hline
                        & NonDet      &  valid     &  invalid    & invalid  \\ \cline{2-5}
        Collection type & OrderNonDet &  invalid   &  valid      & valid    \\ \cline{2-5}
                        & Det         &  invalid   &  invalid    & valid    \\ \hline
    \end{tabular}
    \caption{Valid Collection declarations.  The Collection's type qualifier
        must be a supertype or equal to the element type.}
    \label{fig:determinism-collections}
\end{figure}

The element type of a \<NonDet> collection must be \<NonDet>.
Otherwise, the type qualifier on a collection's element must be a subtype or equal to
the collection's type qualifier (\rulename{collection} rules of
\cref{type-validity}). Note that the \rulename{ordernondet} versions also handle \<Det>,
because $\<Det> \sqsubseteq \<OrderNonDet>$.
\Cref{fig:determinism-collections} restates the \rulename{collection} rules
of
\cref{type-validity}.

\smallskip
\noindent
\begin{minipage}{.48\textwidth}
Some examples of valid types are:
% Using "~" instead of "\ " does not work within \codeid :-(
\begin{Verbatim}[commandchars=\\\{\}]
NonDet      \lptype{List}{NonDet      Int}
OrderNonDet \lptype{List}{OrderNonDet \lptype{Set}{...}}
OrderNonDet \lptype{List}{Det         Int}
Det         \lptype{List}{Det         Int}

\end{Verbatim}
\end{minipage}
\hfill
\begin{minipage}{.46\textwidth}
These types are invalid:
\begin{smaller}
\begin{Verbatim}[commandchars=\\\{\}]
NonDet      \lptype{List}{OrderNonDet \lptype{Set}{...}}
NonDet      \lptype{List}{Det         Int}
OrderNonDet \lptype{List}{NonDet      Int}
Det         \lptype{List}{NonDet      Int}
Det         \lptype{List}{OrderNonDet \lptype{Set}{...}}
\end{Verbatim}
\end{smaller}
\end{minipage}
\smallskip


It is possible to store an expression of type \<Det> in a \<NonDet>
collection, but all elements retrieved from a \<NonDet> collection have
type \<NonDet>.  If the type \ptype{NonDet List}{Det String} were
permitted, the following type hole would exist:

\begin{Verbatim}[commandchars=\\\{\}]
\lptype{Det    List}{Det String} ddlist
\lptype{NonDet List}{Det String} ndlist = ddlist   // permitted by subtyping rules
NonDet Int ni = ...
ndlist[ni] = "anywhere"
\end{Verbatim}

\noindent
The deterministic string \<"anywhere"> is placed in the list at an
arbitrary (that is, nondeterministic) index.  This must be prohibited,
because it unsoundly permits the deterministic list \<ddlist> to differ
from execution to execution.


\subsubsection{Behavior of order-nondeterministic collections}\label{sec:ond-behavior}

A collection of type \<OrderNonDet> has special properties, including the following.

\begin{enumerate}
\item
The individual elements retrieved from it have type \<NonDet>.  This
affects access, iteration, searching, etc.
(Rules \rulename{iteration} and \rulename{next element} in Figure~\ref{fig-ordernondet-rules})
\item
Size-related operations return a deterministic result.  This also affects
queries of whether an iterator has more elements.
\item
If the collection is sorted, or its elements are placed in a collection
that does sorting, the result is deterministic.
\end{enumerate}

To state the first point more formally, the 
typical type for a list access operation, such as \<get>, is
$$\forallt{\tau} \<List>\angles{\tau} \times \<Det Int> \rightarrow \tau$$
but this type is incorrect for \ourTypeSystem.  Each of the following is a
correct (but overly restrictive) type for \<get>:
\begin{eqnarray*}
\forallt{\kappa\ \beta} \<NonDet>\ \<List>\angles{\kappa\ \beta} \times \<Det Int>
& \strut\hspace{-1em} \rightarrow \<NonDet>\ \beta
& \mbox{\quad in this case $\kappa = \<NonDet>$} \\
\forallt{\kappa\ \beta} \<OrderNonDet>\ \<List>\angles{\kappa\ \beta} \times \<Det Int>
& \strut\hspace{-1em} \rightarrow \<NonDet>\ \beta
& \mbox{\quad in this case $\kappa \in \{ \<OrderNonDet>, \<Det> \} $} \\
\forallt{\kappa\ \beta} \<Det>\ \<List>\angles{\kappa\ \beta} \times \<Det Int>
& \strut\hspace{-1em} \rightarrow \<Det>\ \beta\phantom{\<Non>}
& \mbox{\quad in this case $\kappa = \<Det>$}
\end{eqnarray*}

\noindent
and no type introduced so far can express this polymorphism.
(The typing is actually even more complex, because if \emph{either}
argument to \<get> is \<OrderNonDet> or \<NonDet>, then the
result is \<NonDet>.  The above examples only show the case where the index
is deterministic.)
The typical type fro the list access operation only applies if both
arguments are \<Det>,
and our typing must have that as a special case, which is the first line above.






\begin{figure}
%    $\infer[\rulename{iteration}]
%    {\Gamma \vdash \|y| : \|OrderNonDet\ Iterator|\angles{\tau}}
%    {\Gamma \vdash \|x| : \|OrderNonDet \ C\angles{\tau}|
%    & C \sqsubseteq \|Collection|
%    & \|y = C.iterator()|
%    & \wellformed{\tau}
%    }$

    \rulename{iteration}: 
    $
    \forallt{\tau} \|OrderNonDet \ C| \angles{\tau} \rightarrow 
    \|OrderNonDet \ Iterator| \angles{\tau}
    $
    
    \bigskip
    
%    $\infer[\rulename{next element}]
%    {\Gamma \vdash \|z| : \|NonDet \ \beta|}
%    {\Gamma \vdash \|y| : \|OrderNonDet \ Iterator\angles{\kappa \ \beta}|
%        & \|z = y.next()|
%        & \wellformed{\kappa \ \beta}
%    }$

    \rulename{next element}:
    $
    \forallt{kappa \beta} \|OrderNonDet \ Iterator|\angles{\kappa \ \beta} \rightarrow
    \|NonDet|\ \beta
    $
    
    \bigskip
    
%    $\infer[\rulename{hasnext element}]
%    {\Gamma \vdash \|z| : \|Det \ boolean|}
%    {\Gamma \vdash \|y| : \|OrderNonDet \ Iterator\angles{\tau}|
%        & \|z = y.hasNext()|
%        & \wellformed{\tau}
%    }$

    \rulename{hasnext element}:
    $
    \forallt{\tau} \|OrderNonDet \ Iterator|\angles{\tau} \rightarrow
    \|Det \ boolean|
    $
    \bigskip

%    $\infer[\rulename{size}]
%    {\Gamma \vdash \|y| : \|Det \ int|}
%    {\Gamma \vdash \|x| : \|OrderNonDet \ C\angles{\tau}|
%        & C \sqsubseteq \|Collection|
%        & \|y = x.size()|
%        & \wellformed{\tau}
%    }$

    \rulename{size}:
    $
    \forallt{\tau} \|OrderNonDet \ C|\angles{\tau} \rightarrow
    \|Det \ int|
    $
    
\caption{\<OrderNonDet> Collection rules}
\label{fig-ordernondet-rules}
\end{figure}

\subsection{Polymorphism}\label{polymorphism}

This section first describes basic polymorphism over type qualifiers and
over basetypes (\cref{sec:basic-polymorphism}).  Then, it describes two
extensions.
One extension resolves \<OrderNonDet> to \<NonDet> or \<Det> where
needed (\cref{polymorphism-up-down}).
The other extension permits use of polymorphic (type) variables without
affecting binding of those variables --- that is, it affects which
instantiation of an abstraction is chosen at a use site 
(\cref{bindings-uses}).

\todo{Can we come up with more examples of interesting functions to
  describe here?  Or put them in section 3.}


\subsubsection{Qualifier and basetype polymorphism}\label{sec:basic-polymorphism}

\OurTypeSystem supports parametric
polymorphism~\cite{Abadi:1989:FIM:77350.77373,Plotkin:1993:LPP:645891.671433}
over both classes and methods.
A polymorphic abstraction (a class or method) is written and
typechecked once.
It acts as if it has multiple different types, and each use site is
typechecked using the most specific applicable (instantiated,
non-polymorphic) type.



\OurTypeSystem supports both basetype polymorphism and qualifier polymorphism.
When both are applied, it gives the effect of type polymorphism.
Polymorphism applies to both classes and methods.

\todo{Greekify the following}
\begin{itemize}
\item
Type polymorphism has the usual semantics.  For example, the type of the
identity function is $\forallt{\tau} \tau \rightarrow \tau$, which can be
equivalently written as
$\forallt{\kappa \ \beta} \kappa \ \beta \rightarrow \kappa \ \beta$.


\item
  Basetype polymorphism lets the basetype vary indepentently of the
  qualifier, which might be fixed or might be polymorphic.
  An example is a nondeterministic \<choose> function, which might have type

  $\forallt{\beta} \<Set>\angles{\<Det>\ \beta} \rightarrow \<NonDet>\ \beta$

  Basetype polymorphism is rarely used on its own.  Full type polymorphism is more
  common, even if the type is decomposed and the parts used independently,
  as in this more general signature for the \<choose> function:

  $\forallt{\kappa\ \beta} \<Set>\angles{\kappa\ \beta} \rightarrow \<NonDet>\ \beta$

\item
Qualifier polymorphism is common.  For example, here is the signature for
the \<length> method on strings:

$\<length>\ :\ \forallt{\kappa} \kappa\ \<String> \rightarrow \kappa\ \<Int>$

\noindent
and here is that for the addition operation:

$\<plus>\ :\ \forallt{\kappa} \kappa\ \<Int> \times \kappa\ \<Int> \rightarrow \kappa\ \<Int>$

\end{itemize}

Informally, the \<length> method above acts as if it had multiple
(overloaded) definitions

$\<NonDet>\ \<String> \rightarrow \<NonDet> \<Int>$

$\<Det>\ \<String> \rightarrow \<Det> \<Int>$

The body of \<length> must typecheck at every possible instantiation of its
polymorphic function type.  At a use site of \<length>,
the most specific applicable instantiation is chosen.
Here is an example:
\todo{(put it in a table)}

\begin{Verbatim}
NonDet Int ni;
   Det Int di;

plus(ni, ni)  // has type NonDet Int; most specific applicable instantiation is NonDet Int -> NonDet Int
plus(di, di)  // has type Det Int; most specific applicable instantiation is Det Int -> Det Int
plus(ni, di)  // has type NonDet Int; most specific applicable instantiation is NonDet Int -> NonDet Int
\end{Verbatim}

We adopt the convention that  polymorphism is not instantiated in ways
that would create invalid types.  For example, the \<plus> polymorphic
function would not be instantiated at $\kappa = \<OrderNonDet>.$


\subsubsection{Polymorphism rules for collections}\label{polymorphism-up-down}

As described so far, polymorphism cannot express the collection behaviors
of \cref{sec:ond-behavior}.
Consider this potential typing for the \<size> method in class \CollectionE:

$\<size>\ :\ \forallt{\kappa} \kappa\ \CollectionE \rightarrow \kappa\ \<Int>$

\noindent
It cannot be instantiated at $\kappa = \<OrderNonDet>$ as 

$\<size>\ :\ \<OrderNonDet>\ \CollectionE \rightarrow \<OrderNonDet>\ \<Int>$

\noindent
because such an instantiation would include the invalid return type \<OrderNonDet Int>.
This means that the only two instantiations are at 
$\kappa = \<NonDet>$ and $\kappa = \<Det>$.  An invocation on a
\<OrderNonDet> collection would choose the \<NonDet> instantiation and the
size would be \<NonDet Int>.
%
A similar problem occurs for the \<first> operation that returns the first
element of a list.

\OurTypeSystem resolves this problem by introducing two operators over
polymorhic (type) variables, $\uparrow$ and $\downarrow$.
The $\uparrow$ operator converts \<OrderNonDet> to \<NonDet> and leaves the
other qualifiers unchanged.  The upward-pointing arrow is mnemonic for replacing
\<OrderNonDet> by something higher in the type hierarchy.
The $\downarrow$ operator is analogous, but converts \<OrderNonDet> to
\<Det>, which is lower in the type hierarchy.
\Cref{fig:poly-resolutions} formalizes their behavior.



% Not true: We allow Poly(up) and down at every location where Poly is allowed.
%Valid locations for \codeid{@PolyDet("up")} and  \codeid{@PolyDet("down")}:
%$\infer{\wellformed{\kappa \  \beta}}{isParam(\beta) / isReturn(\beta) & \kappa : @PolyDet("up") / @PolyDet("down")}$
%
%Resolution of \<@PolyDet("up")>:\todo{typesetting}
%
%$\infer{\Gamma \vdash x : @NonDet \ \beta_a}{\Gamma \vdash x : \kappa_a \ \beta_a &  \kappa_a : @OrderNonDet/@NonDet & \kappa_p : @PolyDet("up") & \kappa_p \ \beta_p : declaration \ type & \kappa_a \ \beta_a : resolved \ type}$
%
%Resolution of \<@PolyDet("down")>:
%
%$\infer{\Gamma \vdash x : @Det \  \beta_a}{\Gamma \vdash x :  \kappa_a \beta_a & \kappa_a : @OrderNonDet/@Det & \kappa_p : @PolyDet("down") & \kappa_p \ \beta_p : declaration \ type & \kappa_a \ \beta_a : resolved \ type}$


%\Cref{fig-poly-resolution} presents the rule for type checking of methods annotated with \<PolyDet> or its variants.

The correct type for \<size> is

$\<size> : \forallt{\kappa} \kappa\ \CollectionE \rightarrow \down{\kappa}\ \<Int>$

\noindent
This can be instantiated at all three type qualifiers without creating any
invalid types:

$\<size> : \<NonDet>\ \CollectionE \rightarrow \<NonDet>\ \<Int>$

$\<size> : \<OrderNonDet>\ \CollectionE \rightarrow \<Det>\ \<Int>$

$\<size> : \<Det>\ \CollectionE \rightarrow \<Det>\ \<Int>$

\noindent
The above instantiations implement the semantics of \cref{sec:ond-behavior}.

An example use of $\uparrow$ is in the \<first> method in class \ListKB\ that
returns the first element of a list.  Its type is

$\<first> : \forallt{\kappa} \kappa\ \ListKB \rightarrow \up{\kappa}\ \beta_e$

\noindent
which can be instantiated as

$\<first> : \<NonDet>\ \ListKB \rightarrow \<NonDet>\ \beta_e$

$\<first> : \<OrderNonDet>\ \ListKB \rightarrow \<NonDet>\ \beta_e$

$\<first> : \<Det>\ \ListKB \rightarrow \<Det>\ \beta_e$

\todo{As I mentioned in email, $\<NonDet>\ \beta_e$ looks wrong to me,
  because $\beta_e$ may be a collection whose type arguments are not
  compatible with \<NonDet>.  Maybe just remark that the instantiation does
  not happen in that case.  If we try to adjust the type arguments to fit
  \<NonDet>, then unsoundness occurs.}


%\begin{figure}
%    $\infer[\rulename{poly resolution}]{\pi_r \ \beta_r\ \<m>(\overline{\pi_i \ \beta_i})\{\ \}}{\forallt{\kappa \in \{\|NonDet, OrderNonDet, Det|\}} \kappa \ \beta_r\ \<m>(\overline{K \ \beta_i})\{\ \} & \pi_r, \pi_i \in \{\|PolyDet|, \PolyDetUp, \PolyDetDown    \}}$
%    \caption{Polymorphic resolution rule}
%    \todo{I'm not sure what this is doing.  What code does it reject?}
%    \todo{This suggests that \PolyDetUp is a qualifier, rather than
%      $\uparrow$ being an operator on qualifiers.  We should clarify which
%      it is.}
%    \label{fig-poly-resolution}
%\end{figure}

%\begin{table}[]
%    \begin{tabular}{|l|l|l|}
%        \hline
%        \textbf{\<PolyDet>} & \textbf{\PolyDetUp} & \textbf{\PolyDetDown} \\ \hline
%        \<NonDet> & \<NonDet> &  \<NonDet>\\ \hline
%        \<OrderNonDet> & \<NonDet> &  \<Det>\\ \hline
%        \<Det> & \<Det> &  \<Det>\\ \hline
%    \end{tabular}
%\caption{Polymorphic resolution}
%\todo{Write this as a rule rather than a table.}
%\label{tab-poly-resolutions}
%\end{table}

\begin{figure}
    $\infer[\rulename{ordernondet polyup}]
    {\up{\tau} = \|NonDet \ \beta|}
    {\tau = \|OrderNonDet \ \beta|
        & \wellformed{\tau}
    }$

    \bigskip
    
    $\infer[\rulename{polyup}]
    {\up{\tau} = \kappa \ \beta}
    {\tau =\kappa \ \beta
        & \kappa \in \{\|Det, NonDet|\}
        & \wellformed{\tau}
    }$

    \bigskip

    $\infer[\rulename{ordernondet polydown}]
    {\down{\tau} = \|Det \ \beta|}
    {\tau = \|OrderNonDet \ \beta|
        & \wellformed{\tau}
    }$
    
    \bigskip
    
    $\infer[\rulename{polydown}]
    {\down{\tau} = \kappa \ \beta}
    {\tau =\kappa \ \beta
        & \kappa \in \{\|Det, NonDet|\}
        & \wellformed{\tau}
    }$
\caption{Polymorphic resolution of $\uparrow$ and $\downarrow$ operators ($\uparrow$ is overloaded for types and qualifiers)}
\todo{I think this needs to do something to nested collections.  Or maybe
  just clarify that if there is a nested collection such that this would
  yield an invalid type, then the instantiation does not apply.  That might
  be cleanest.}
\label{fig:poly-resolutions}
\end{figure}

\subsubsection{Differentiating binding and use}\label{bindings-uses}

A simplified type for the list \<get> method for lists of strings is

$\<get> : \forallt{\kappa} \kappa\ \<List>\angles{\kappa\ \<String>} \times \kappa\ \<Int> \rightarrow \kappa\ \<String>$
\todo{Used to be $\up{\kappa}$ for return type, but I don't think that is needed.}
\todo{Oh, maybe it's because we need to be able to instantiate in the tye
  parameter differently?  How do we enable that?}

(The actual typing permits the qualifier on the type argument to differ
from the type qualifier on the list, and it handles arbitrary basetypes
including collections that may themselves be order-nondeterministic.)

Instantiations are:

$\<get> : \<NonDet List>\angles{\<NonDet String>} \times \<NonDet Int> \rightarrow \<NonDet String>$

$\<get> : \<Det List>\angles{\<Det String>} \times \<Det Int> \rightarrow \<Det String>$

\todo{We don't need the OrderNonDet instantiation.  The other two
  instantiations are enough.
  We don't need the following instantiation:}
\begin{Verbatim}
   // instantiation: OrderNonDet List<Det String> x _ Int -> NonDet String 
\end{Verbatim}

If either the list or the index is (order) non-deterministic, then the result is
nondeterministic:

\begin{Verbatim}
NonDet Int ni;
   Det Int di;
NonDet List<NonDet String> nl;
OrderNonDet List<Det String> ol;
Det List<Det String> dl;

get(nl, ni) : NonDet String // instantiation: NonDet List<NonDet String> x NonDet Int -> NonDet String
get(nl, di) : NonDet String
get(ol, ni) : NonDet String
get(ol, di) : NonDet String
get(dl, ni) : NonDet String
get(dl, di) : Det String    // instantiation: NonDet List<Det String> x Det Int -> Det String
\end{Verbatim}


A similar typing does \emph{not} work for the \<set> function that sets an
element of a list, because it would permit a deterministic collection to
be side-effected in non-deterministic ways.  Consider the following
possible type for

$\<set> : \forall \forallt{\tau}$

qualifier 
on the List add method: \codeid{public void add(PolyDet ArrayList<E> this, PolyDet int index, E element)}.
Suppose a client calls this method as follows:
\begin{verbatim}
@Det ArrayList<@Det String> list;
@NonDet int random;
@Det String str;
list.add(random, str);
\end{verbatim}
This will result in the instantiation \codeid{public void add(@NonDet ArrayList<E> this, @NonDet int index, E element)} and
the method invocation will type check. This is problematic because even though \<list> was declared to be \<Det>,
the type checker allows the addition of an element at a \<NonDet> location violating our determinism guarantees.
We prevent this behavior by introducing another variant of \<PolyDet>, \<PolyDet("use")> that does not affect
type instantiations. This is especially useful in preventing methods from non-deterministically modifying the state
of a deterministic receiver. To have this effect, the library method \<ArrayList.add> is annotated as:
\codeid{public void add(PolyDet ArrayList<E> this, PolyDet("use") int index, E element)}.
Since \<PolyDet("use")> has no effect on type instantiations, calling this method on a \<Det List>
will result in the method declaration being instantiated as \codeid{public void add(@Det ArrayList<E> this, @Det int index, E element)}
irrespective of the type of \<index>, thereby preventing undesired side-effects.


\subsection{Dataflow analysis and type refinement}\label{dataflow}
\TheDeterminismChecker performs local type inference within method bodies.
It does not perform whole-program type inference.
This makes separate compilation possible.
It forces programmers to write specifications (type qualifiers) on methods,
which is good style and valuable documentation.

The local type inference is flow-sensitive.  That is, each variable may
have a different type on every line of the program, depending on
assignments to the variable.  The inferred type always respects any
declared type:  that is, it is always a refinement (a subtype) of the
declared type, if any.

In addition to assignments, some method calls refine the types of their
arguments.  One example is the \<sort> routine, as shown in 
as shown in \cref{fig-sorting}.  One notable fact about the \rulename{sort}
rule is that it requires the type argument to be deterministic (type
qualifier \<Det>).  This is necessary because of two constraints.
First, refinement must not change the type argument, because of invariant
type argument subtyping.
Second, the only possible type argument for a \<Det> collection is \<Det>.


It is not permitted to 




\TheDeterminismChecker has additional type refinement rules for the sorting
methods of \<List>, \<Collections>, and \<Arrays> classes
\begin{figure}
%     $\infer[\rulename{list sort}]{\Gamma \vdash x : \|Det \ List|\angles{\|Det| \ \beta}}{\Gamma \vdash x : \|OrderNonDet \ List|\angles{\|Det| \ \beta} & \|x.sort()|}$
%     
%     \bigskip
    
  $\infer[\rulename{sort}]
  {\Gamma \vdash x : \<Det List>\angles{\<Det>\ \beta}}
  {\Gamma \vdash x : \<OrderNonDet List>\angles{\<Det>\ \beta} & \<sort(x)>}$
    
%     \bigskip
%     
%     $\infer[\rulename{arrays sort}]{\Gamma \vdash x : \|Det \ \beta \ Det[]| }{\Gamma \vdash x : \|Det \ \beta \ OrderNonDet[]| & \|Arrays.sort( \ x)|}$
    
    \caption{Sorting type refinement rules.  \<sort> is a method that works
    by side effect and changes the value---and the type---of its receiver.}
\todo{These don't capture the notion of ``the type \emph{after} the sort call''.}
    \label{fig-sorting}
\end{figure}
\TheDeterminismChecker type refines a receiver of type \codeid{OrderNonDet List} to a \codeid{Det List} if all the
type argument of this \codeid{List} have the type qualifier \codeid{Det} (Rule \rulename{sort} in \cref{fig-sorting}).
As per these rules, if \codeid{sort()} is called on a receiver of type \codeid{OrderNonDet List<Det Set<Det String>>}, it will
be type refined to \codeid{Det List<Det Set<Det String>>}. However a receiver of type \codeid{OrderNonDet List<OrderNonDet Set<Det String>>} will not be type refined.

%\subsection{CLIMB-to-top and collection, array locals}\label{climb-rules}
%
%Every type system in the checker framework must define a default type qualifier. This qualifier will be applied
%to every location that isn't explicitly annotated. In our determinism checker, we chose \codeid{@Det} as the default qualifier.
%The reason for this design choice is that we expect the program to be 
%deterministic unless specified by programmer or the program calls nondeterministic library methods that we have annotated 
%(Random, Collections, etc).
%The framework applies the CLIMB-to-top rule. This rule states that the \textit{top} qualifier 
%in the hierarchy is the default for the CLIMB locations: Casts, Locals, Instanceof, and (some) iMplicit Bounds. The rationale
%for this rule is as follows:
%
%\begin{itemize}
%    \item Local variables are defaulted to top because type refinement is applied to local variables. If a local variable starts as the 
%    \textit{top} type, then the Checker Framework refines it to the best (most specific) possible type based on assignments to it. As a 
%    result, a programmer rarely writes an explicit qualifier on any of those locations.
%    Variables defaulted to top include \textit{local variables}, resource variables in the \textit{try-with-resources} construct, variables 
%    in \textit{for} statements, and \textit{catch} arguments (known as exception parameters in the Java Language Specification). 
%    \textit{Exception parameters} need to have the \textit{top} type because exceptions of arbitrary qualified types can be thrown 
%    and the Checker Framework does not provide runtime checks.
%    \item \textit{Cast} and \textit{instanceof} types are given the same type as their argument expression. This has the same effect as 
%    if they were given the \textit{top} type and then flow-sensitively refined to the type of their argument.
%    \item Implicit upper bounds are defaulted to top to allow them to be instantiated in any way. If a user declared class \codeid{C<T> 
%        { ... }}, then the Checker Framework assumes that the user intended to allow any instantiation of the class, and the declaration
%    is interpreted as class \codeid{C<T extends @NonDet Object> { ... }} rather than as class \codeid{C<T extends @Det Object> { ... }}. The latter would forbid instantiations such as \codeid{C<@Det String>}, or would require rewriting of code. On the other hand, if a user writes 
%    an explicit bound such as class \codeid{C<T extends D> { ... }}, then the user intends some restriction on instantiation and can write a 
%    qualifier on the upper bound as desired.
%    This rule means that the upper bound of class \codeid{C<T>} is defaulted differently than the upper bound of class \codeid{C<T extends Object>}. 
%    This may seem confusing, but it is the least bad option. The more confusing alternative would be for \codeid{Object} to be defaulted 
%    differently in class \codeid{C<T extends Object>} and in an instantiation \codeid{C<Object>}, and for the upper bounds to be defaulted differently 
%    in class \codeid{C<T extends Object>} and class \codeid{C<T extends Date>}.
%    \item \textit{Implicit lower bounds} are defaulted to the \textit{bottom} type, again to allow maximal instantiation. Note that Java does not allow a programmer to express both the upper and lower bounds of a type, but the Checker Framework allows the programmer to specify either or both.
%\end{itemize}
%With the above rules, the checker framework will automatically annotate a local collection with type \<@NonDet> and its
%type arguments will get the type \<@Det>. For example, a locally declared \codeid{List} of \codeid{Strings} will be automatically annotated
%as \codeid{@NonDet List<@Det String>}. Recall from~\cref{collection-rules} that \theDeterminismChecker does not allow this type on
%any collection. While this is still sound, it will result in \theDeterminismChecker reporting a lot of errors because every locally declared 
%collection gets annotated with this invalid type. To avoid this situation, we make an exception to the defaulting rules for local collections
%and annotate their type parameters also with \<@NonDet>. So a local list of Strings gets the default qualifier of \codeid{@NonDet List<@NonDet String>}. While this defaulting eliminates the possibility of automatically annotating locals collections with an invalid
%type, it would could in a high number of false positives. In the following code snippet,
%\begin{verbatim}
%void test(@Det List<@Det String> argList) {
%List<String> localList = argList;
%}    
%\end{verbatim}
%\theDeterminismChecker would report an error at the assignment statement since the inferred type for \codeid{localList} is 
%\codeid{@NonDet List<@NonDet> String} and since collections types are invariant.
%We therefore recommend that programmers explicitly annotate
%all local variables that are collections to reduce false positives. The same reasoning and recommendation applies to arrays.

\subsection{Maps}\label{maps}
A map is a collection of keys--value pairs.
Like other collections, a map can be nondeterministic,
order-nondeterministic, or deterministic.
Analogously to set membership, lookups are deterministic in
order-nondeterministic and deterministic maps; in addition, the iteration
order is fixed in a deterministic map.

We explain why each of these is possible by considering three common
implementation strategies.

A hash table is order-nondeterministic, because hash codes are
nondeterministic in general.

A hash table can be augmented by a linked list recording insertion order,
so that iteration order is deterministic.

A map can be backed by a sorted collection, such as a tree.  Such a map is
either \<NonDet> (if \<NonDet> keys or values are inserted into it) or
\<Det>, but never \<OrderNonDet>.


\subsection{Determinism checker specific rules for precision}\label{precision}
We annotated the \codeid{equals()} method of the \<Set> class in the JDK as
\begin{verbatim}
PolyDet("down") boolean equals(PolyDet Set<E> this, PolyDet Object o)
\end{verbatim}
While this is sound, it is imprecise in the case of \codeid{OrderNonDet
  Set}s.\todo{Explain why.}
 We added the following rule shown in \cref{fig-precision-rules} to our checker to improve precision.
\begin{figure}
    \todo{add line break}
    $\infer[\rulename{set precision}]{\Gamma \vdash \|x.equals(y) : Det|}{\Gamma \vdash \|x| : \|OrderNonDet| \ \|Set|\angles{ \kappa_{x} \ \beta_{x}}, \|y| : \|OrderNonDet| \ \|Set|\angles{ \kappa_{y} \ \beta_{y}} & \kappa_{x} \ \beta_{x} \nsqsubseteq \|OrderNonDet \ List| & \kappa_{y} \ \beta_{y} \nsqsubseteq \|OrderNonDet \ List| }$
    
    \bigskip
    
    $\infer[\rulename{map precision}]{\Gamma \vdash \|x.get(y) : Det|}{\Gamma \vdash \|x : OrderNonDet \ Map\angles{ Det \ \beta_k, \kappa_v\ \beta_v }, y : Det \ \beta|}$
    
    \caption{Improving precision}
\todo{In the \rulename{map precision} rule, should the \<Det> in the
  conclusion be $\beta_v$?}
    \label{fig-precision-rules}
\end{figure}
According to this rule, if the \<Set> receiver has type \codeid{@OrderNonDet Set<@Det List>} and the argument to the \codeid{equals()} method is
also of the same type, the return type gets the qualifier \<Det>. Without this precision rule, the return type would have been instantiated as \<NonDet> which
is sound but imprecise. This rule is careful enough to not annotate the return type of \<equals()> as \<Det> if a type argument to either the
receiver or the argument happens to be an \codeid{OrderNonDet List}.
\todo{The following is the key!  Put in earlier.}(An order nondeterministic list does not provide any guarantee on the
equality as it is dependent on the iteration order). 

Similarly, the \codeid{get()} method in the \<Map> class is annotated with polymorphic qualifiers and the rule \rulename{map precision}\ in \cref{fig-precision-rules} improves precision for \<OrderNonDet> receivers.

\subsection{Extending \ourTypeSystem}\label{extending-det-checker}
We have primarily focused on collections and annotated the corresponding classes in the JDK.
These qualifiers provide machine verifiable specifications of determinism properties.
Another source of nondeterminism that we haven't analyzed closely is the File system methods.
A program analysis developer interested in verifying determinism guarantees with respect to 
the File system can easily do so by annotating the parameter and return types of those methods in the JDK.
Alternatively, a user can write these qualifiers in a \textit{stub} file and supply it to the type checker. A \textit{stub}
only needs to contain method declarations along with their qualifiers.

% LocalWords:  basetypes NonDet OrderNonDet Det Iterable formedness param1
% LocalWords:  PolyDet boolean param2 arg1 arg2 localList entrySet keySet
% LocalWords:  LinkedHashMap TreeMap HashSet LinkedHashSet LinkedHashSet's
