\section{Related work}\label{sec:related}

The state of the art for detecting nondeterministic tests is
NonDex~\cite{ShiGLM2016}.  It is a highly effective tool.
% https://github.com/TestingResearchIllinois/NonDex/wiki/Supported-APIs
NonDex uses a hand-crafted list of 47 methods (25 unique method names)
in 13 classes as potential sources of flakiness. 
For each of the identified methods, the authors built models that
return different results when called consecutively. A modified JVM then
runs a given test multiple times and reports the test as being flaky if it observes
diverging test output. While this approach produces precise results, it requires manual inspection
and considerable debugging effort to locate and fix the source of flakiness. \TheDeterminismChecker, in
contrast, reports the cause of nondeterminism at compile time requiring
little to no debugging effort.  However, \theDeterminismChecker requires
much more upfront effort, and it produces false positive warnings.
NonDex's approach of identifying and modeling methods with nondeterministic
specifications is analogous to our library specifications. So far, we have annotated
928 methods across 41 classes in the JDK, in addition to other libraries.
%\todo{Check whether our JDK is missing anything they support - No}
%\todo{Did the NonDex authors contact the maintainers of the tools in which
%  they found nondeterminism - No!}
%\todo{The NonDex authors didn't contact the maintainers of tools.
%From the paper: "NonDex detected 57 previously unknown
%flaky tests in open-source projects and three flaky tests
%that have been already fixed by the open-source software
%developers."}

DeFlaker~\cite{BellLHEYM2018} is another approach for flaky test detection. It
relies on a
version control history. It computes a diff of the code covered
in the current version and the previous one. If there exists a test case whose code coverage does not include
this diff but still produces different results on the two versions being compared, it is flagged as being flaky.
This approach doesn't require JVM modifications
and integrates easily with production software. DeFlaker reported 19 previously unknown bugs
in open source projects, 7 of which were addressed by the developers of these projects. DeFlaker is agnostic
to the code under test and can therefore report flakiness arising out of concurrency, which \theDeterminismChecker cannot.

Nondeterminism in tests is of interest to both
researchers and software developers alike~\cite{Fowler,Sudarshan}.
Luo et al.~\cite{LuoHEM2014} studied 51 open source projects and analyzed the most common root causes of
test flakiness. The findings suggest that most of the flakiness in tests is caused by
the use of async await, concurrency, or due to test order dependency. The authors of~\cite{PlotkinA1993}
perform an empirical study on open source benchmarks, the results of which concur with those of~\cite{LuoHEM2014}.
Additionally,~\cite{PlotkinA1993} studies the effects of removing these test smells. The results suggest that
refactoring the test code smells fixed more than half of the identified flaky tests. Our approach is complementary to
these techniques and aims to prevent nondeterminism from causing harmful effects. 

%\todo{I don't see how the first two (especially the first) citations in the
%  next paragraph are related to our work.  Make the connection explicit, or
%  remove them.}

The problem of inconsistencies between specifications and implementations
is quite prevalent. Other researchers have explored ways of reducing the gap between implicit
specifications in APIs and the assumptions made by their clients in a variety of problem domains.
The findings in~\cite{Jin:2012:UDR:2254064.2254075} suggest that incorrect understanding of performance specifications of 
APIs is a very common root cause for
performance bugs. ~\cite{Rui:2013:180377} analyzes the APIs related to security such as authorization and authentication.
These APIs which come as a part of the SDKs provided by online providers are used by application developers to 
build secure apps. The paper discovers that the security guarantees provided by these SDKs are violated due to
the implicit assumptions made by the APIs that the users are unaware of. In \cite{Xiao:2014:NMC:2591062.2591177},
the authors
study the effect of nondeterminism in MapReduce programs with a specific focus on nondeterminism caused by
non-commutative reducers. While they found bugs that violated correctness due to this bug pattern,
the authors reported that several of these were harmless as they relied on an implicit assumption on data
which ensured correctness. 

Several techniques have been proposed to test whether a
deterministic implementation conforms to its nondeterministic finite state machine~\cite{Petrenko1996,Petrenko:1993:NSM:648128.761244,Savor:1997:639710,Hierons:2004:TCD:1040993.1040998}.
\cite{Cook:2013:RNP:2491956.2491969} presents an approach that can automatically verify properties
in branching time temporal logic systems that are inherently
nondeterministic.
Bocchino et
al.~\cite{Bocchino:2009:TES:1640089.1640097,Bocchino:2011:SND:1926385.1926447}
present a type-and-effect system that provides compile-time determinism
guarantees for parallel programs, with a focus on barrier removal,
reasoning about interference and thread interleavings.
We believe our work to be the first verification approach
aimed at ensuring determinism in sequential programs.

Failing tests that are unrelated to code changes can be expensive both in terms of monetary costs and
developer effort. \cite{Herzig:2015:EDF:2819009.2819018} proposes techniques to classify tests as false alarms
if they are known to be caused by testing infrastructure or other environment issues.~\cite{Huo:2014:IOQ:2635868.2635917}
presents an approach that detects brittle assertions in tests by performing a taint analysis on inputs classified as 
controlled and uncontrolled.~\cite{ZhangJWMLEN2014} investigates the
effects of the test independence assumption
on other techniques such as test prioritization, selection, etc. Other approaches~\cite{BellKMD2015,GyoriSHM2015}
analyze test dependencies and either prevent them or use this information for other optimizations.
The approaches in \cite{Dan:2013:10.1007/978-3-642-39038-8_25,Vahabzadeh:2015:7332456} focus on differentiating bugs due to tests
from those caused by source code. While we haven't fully accounted for all nondeterministic sources due
to the environment, our technique is easily extensible by adding annotations to the corresponding classes.

%\todo{A NonDet annotation:
%  \url{http://www.swi-prolog.org/pldoc/man?section=modes}}

%% Added this info in the experiments section
%\todo{All nondeterminism that NonDex found was due to 7 methods in 3 classes:
%Class\#getDeclaredFields
%Class\#getDeclaredMethods
%Class\#getFields
%DateFormatSymbols\#getZoneStrings
%HashMap\#entrySet
%HashMap\#keySet
%HashMap\#values
%}
